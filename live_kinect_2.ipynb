{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### import library for kinect\n",
    "import cv2\n",
    "from pykinect2 import PyKinectV2\n",
    "from pykinect2 import PyKinectRuntime\n",
    "import numpy as np\n",
    "import datetime\n",
    "import scipy.io \n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from data_loader_jpeg import VideoFolder\n",
    "from model import ConvColumn\n",
    "from torchvision.transforms import *\n",
    "from PIL import Image\n",
    "gpus = [0,0]\n",
    "best_prec1 = int(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # set run output folder\n",
    "model_name = \"jester_conv_example\"\n",
    "start = time.time()\n",
    "# create model\n",
    "model = ConvColumn(7)\n",
    "\n",
    "# multi GPU setting\n",
    "model = torch.nn.DataParallel(model, device_ids= gpus).cuda()\n",
    "\n",
    "if os.path.isfile(\"checkpoint.pth.tar\"):\n",
    "    print(\"=> loading checkpoint\")\n",
    "    checkpoint = torch.load(\"checkpoint.pth.tar\")\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint (epoch {})\"\n",
    "          .format(checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found \")\n",
    "\n",
    "cudnn.benchmark = False\n",
    "print(time.time() - start)\n",
    "gestures = ['Swiping_Left', 'Swiping_Right', 'Swiping_Down', 'Swiping_Up', 'Zooming_In', 'Zooming_Out', 'Doing_other_things']\n",
    "colors = [(255,0,0),(0,255,0),(0,0,255),(0,255,255),(255,255,0),(255,0,255),(255,255,255)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GestureBrain():\n",
    "    \n",
    "    def __init__(self,  model ):\n",
    "        self.curr_stream = []\n",
    "        self.model = model \n",
    "        self.counter  = 0 \n",
    "\n",
    "    def adjust_judge_sequence(self):\n",
    "        frame_diff = len(self.curr_stream) - 18 \n",
    "        if  frame_diff == 0 :\n",
    "            return self.curr_stream\n",
    "        elif frame_diff > 0 :\n",
    "            return self.curr_stream[frame_diff:]\n",
    "        else :\n",
    "            return self.curr_stream[:1] * abs(frame_diff) + self.curr_stream\n",
    "\n",
    "    def prepreocess_img (self,  img_array):\n",
    "        \n",
    "#        img_array = (img_array / 255.)\n",
    "#         img_array  = cv2.resize(img_array ,(149,84), interpolation = cv2.INTER_CUBIC)\n",
    "        img_array = cv2.resize(img_array, (149, 84))\n",
    "#        img_array = np.array(img_array, dtype=np.float32)\n",
    "        img_array = Image.fromarray(img_array.astype('uint8'), 'RGB')\n",
    "        transform = Compose([\n",
    "        CenterCrop(84),\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                  std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        img_array = transform(img_array)\n",
    "        return (img_array)\n",
    "    \n",
    "\n",
    "    def push_img (self, img):\n",
    "\n",
    "        img = self.prepreocess_img(img )\n",
    "        self.curr_stream.append(torch.unsqueeze(img, 0))\n",
    "        if len( self.curr_stream ) > 18 :      ## limit 18 frames\n",
    "            self.curr_stream.pop(0)\n",
    "\n",
    "            \n",
    "    def regonize(self):\n",
    "        \n",
    "        self.curr_stream = self.adjust_judge_sequence()\n",
    "        data = torch.cat(self.curr_stream)\n",
    "        data = data.permute(1, 0, 2, 3)\n",
    "        data = data.unsqueeze(0)\n",
    "        input = data\n",
    "        \n",
    "        input_vars = Variable(input)\n",
    "        output = model(input_vars)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        predicted = predicted.cpu().numpy()\n",
    "        predicted = predicted[0]\n",
    "        gestures = ['Swiping_Left', 'Swiping_Right', 'Swiping_Down', 'Swiping_Up', 'Zooming_In', 'Zooming_Out', 'Doing_other_things']\n",
    "        print('predict_gesture: {}'.format(gestures[predicted]))\n",
    "        index = predicted\n",
    "# clear  for 1 action        \n",
    "#         if index != 6 :\n",
    "# #             print(\"cleaning!\")\n",
    "# #             self.curr_stream = []         \n",
    "        return index \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##### optimize gestures\n",
    " \n",
    "gt = ['Doing_other_things']\n",
    "gt = gt * 8    ##  number of threshold\n",
    "b = ['Doing_other_things','Doing_other_things']\n",
    "c = 'Doing_other_things'\n",
    "\n",
    "\n",
    "def gestures_opt(act):\n",
    "    \n",
    "    gt.append(act)\n",
    "#     if gt[-1] == gt[-2] == gt[-3] == gt[-4] == gt[-5]== gt[-6] == gt[-7] == gt[-8] == gt[-9] == gt[-10]:\n",
    "    if gt[-1] == gt[-2] == gt[-3] == gt[-4] == gt[-5]== gt[-6]== gt[-7] == gt[-8] :    \n",
    "        b.append(gt[-1])\n",
    "    else:\n",
    "        b.append('Doing_other_things')\n",
    "    b.pop(0)\n",
    "    if b[-1] != b[-2]:\n",
    "        c = b[-1]\n",
    "    else:\n",
    "        c = 'Doing_other_things'\n",
    "    print(c)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"prediction_file.txt\",\"w\")\n",
    "file.close()  \n",
    "\n",
    "file = open(\"prediction_file1.txt\",\"w\")\n",
    "file.close()  \n",
    "\n",
    "# get frame by  Kinect\n",
    "kinect = PyKinectRuntime.PyKinectRuntime(PyKinectV2.FrameSourceTypes_Color | PyKinectV2.FrameSourceTypes_Body)\n",
    "print(type(kinect))\n",
    "\n",
    "# Get one color picture frame\n",
    "cv2.namedWindow('Color Image', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Color Image', int(1920/2), int(1080/2))\n",
    "\n",
    "frame = None\n",
    "cnt = 0\n",
    "x0 = 500\n",
    "y0 = 500\n",
    "h = 490/2\n",
    "w = 650/2\n",
    "blue_color = (255,0,0)\n",
    "\n",
    "def draw_rectangle(img, x0, y0, color):\n",
    "    # ok, at least one is good \n",
    "    w = 406\n",
    "    h = 406\n",
    "    s1 = (int(x0 - w),int(y0 + h))      #### note: may be  transfer x to y\n",
    "    s2 = (int(x0 + w),int(y0 + h))\n",
    "    s3 = (int(x0 + w),int(y0 - h))\n",
    "    s4 = (int(x0 - w),int(y0 - h))\n",
    "    cv2.line(img,s1,s2,color,5)\n",
    "    cv2.line(img,s2,s3,color,5)\n",
    "    cv2.line(img,s3,s4,color,5)\n",
    "    cv2.line(img,s4,s1,color,5)\n",
    "\n",
    "counter = 0 \n",
    "gb = GestureBrain(model)\n",
    "while(True):\n",
    "\n",
    "#     colorFrame = kinect.get_last_color_frame()\n",
    "#     colorFrame = colorFrame.reshape((1080,1920,4))\n",
    "#     cv2.imshow(\"Color Image\", colorFrame)\n",
    "    start = timeit.default_timer()  \n",
    "    # gb = GestureBrain(model)\n",
    "    \n",
    "    if (kinect.has_new_body_frame()): \n",
    "        bodies = kinect.get_last_body_frame()\n",
    "        if bodies is not None: \n",
    "            colorFrame = kinect.get_last_color_frame()            \n",
    "            for i in range(0, kinect.max_body_count):\n",
    "                body = bodies.bodies[i]      ##### set i =1 ???\n",
    "                if not body.is_tracked: \n",
    "                    continue\n",
    "                joints = body.joints\n",
    "                # convert joint coordinates to color space \n",
    "                joint_points = kinect.body_joints_to_color_space(joints)     ### joint in color spaces\n",
    "                joint0 = PyKinectV2.JointType_SpineShoulder\n",
    "                x0 = joint_points[joint0].x\n",
    "                y0 = joint_points[joint0].y  \n",
    "                \n",
    "                #### convert to RGB frames\n",
    "#                 colorFrame = kinect.get_last_color_frame()\n",
    "                colorFrame = colorFrame.reshape((1080,1920,4))\n",
    "                rgb_frame = colorFrame[:,:,:-1]\n",
    "                \n",
    "                \n",
    "                ######## draw block\n",
    "                draw_rectangle(colorFrame, x0, y0, colors[i])\n",
    "                   \n",
    "                \n",
    "                ########### boclk frame (note: may be change x,y)\n",
    "                h1 = 480/2\n",
    "                w1 = 640/2\n",
    "                cnt = cnt + 1                        \n",
    "\n",
    "                    \n",
    "                roi_frame = rgb_frame[int(y0- h1):int(y0 + h1),int(x0 -w1):int(x0 + w1),:]\n",
    "                print(np.shape(roi_frame))\n",
    "                \n",
    "                counter += 1\n",
    "#                 time.sleep(0.05)\n",
    "\n",
    "                \n",
    "                gb.push_img(roi_frame)\n",
    "                \n",
    "#                 if counter != 18 :\n",
    "#                     continue \n",
    "#                 else:\n",
    "#                     counter = 0 \n",
    "                \n",
    "                action = gb.regonize()\n",
    "                act_name = gestures[action]\n",
    "                predict_gesture = gestures_opt(act_name)\n",
    "                \n",
    "                                \n",
    "                file = open(\"prediction_file1.txt\", \"a\")\n",
    "                file.writelines(\"%s \\n\" % (predict_gesture))\n",
    "                file.close()\n",
    "                                \n",
    "                file = open(\"prediction_file.txt\", \"a\")\n",
    "                file.writelines(\"%s \\n\" % (gestures[action]))\n",
    "                file.close()              \n",
    "                \n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#                 cv2.putText(colorFrame,'{}'.format(gestures[action]),(int(x0 - w),int(y0 - h)), font, 2 ,(0,255,0),2,cv2.LINE_AA)\n",
    "#                cv2.putText(colorFrame,'predict_gesture_per_frame: {}'.format(gestures[action]),(int(80),int(80)), font, 2 ,(255,0,0),2,cv2.LINE_AA)                \n",
    "                if predict_gesture != 'Doing_other_things': \n",
    "                    cv2.putText(colorFrame,'{}'.format(predict_gesture),(int(500),int(300)), font, 3 ,(255,0,255),2,cv2.LINE_AA)\n",
    "                cv2.imshow(\"Color Image\", colorFrame)\n",
    " \n",
    "                if predict_gesture != 'Doing_other_things': \n",
    "                    key = cv2.waitKey(750)\n",
    "                    time.sleep(0.8)\n",
    "                    gb.curr_stream = []\n",
    "                    \n",
    "                    \n",
    "                 \n",
    "                \n",
    "\n",
    "#                 if action != 6 :\n",
    "#                      key = cv2.waitKey(150)\n",
    "#                 path = 'D:\\\\Hand_Gesture_Recognition_System\\\\RGB_Output'\n",
    "#                 fmtname = datetime.datetime.today().strftime(\"%y%m%d_%H%M%S\")\n",
    "#                cv2.imwrite('{}\\\\Color_{}_roi_{}.png'.format(path, fmtname, cnt), roi_frame)\n",
    "                pass\n",
    " \n",
    "    key = cv2.waitKey(20)\n",
    "    if  key == 27:\n",
    "        break\n",
    "    stop = timeit.default_timer()\n",
    "    fps = 1/(stop-start)\n",
    "    \n",
    "    print(\"Estimated fps : {0}\".format(fps))\n",
    "cv2.destroyAllWindows()\n",
    "kinect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
